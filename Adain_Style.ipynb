{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adain_Style.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptran1203/style_transfer/blob/master/Adain_Style.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7z-woM6V8MW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d4d2ed04-b41e-4ed1-d0fd-82e40895ed0e"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from google.colab import drive, output\n",
        "data_loaded = False\n",
        "drive.mount('/content/drive')\n",
        "BASE_DIR = \"/content/drive/My Drive/Style_Transfer\"\n",
        "!rm -rf '/content/style_transfer'\n",
        "!git clone https://github.com/ptran1203/style_transfer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Mounted at /content/drive\n",
            "Cloning into 'style_transfer'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 352 (delta 18), reused 77 (delta 12), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (352/352), 56.37 MiB | 10.98 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWPPRy7y-0jy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3806876-8318-4da6-d3f6-df83109346fe"
      },
      "source": [
        "cd style_transfer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/style_transfer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asS8B2UYR4iR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "abfedcb6-adc6-42e7-b07b-c05bb0cde8df"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import utils\n",
        "from dataloader import DataGenerator\n",
        "from model import *\n",
        "\n",
        "class DataGen(DataGenerator):\n",
        "    BATCH_FILES= 4\n",
        "\n",
        "class SModel(StyleTransferModel):\n",
        "    def compute_style_loss(self, gen_img, style_img):\n",
        "        gen_feats = self.style_layers(gen_img)\n",
        "        style_feats = self.style_layers(style_img)\n",
        "        style_loss = []\n",
        "        axis = [1, 2]\n",
        "        for i in range(len(style_feats)):\n",
        "            gmean = K.mean(gen_feats[i], axis=axis)\n",
        "            gstd = K.std(gen_feats[i], axis=axis)\n",
        "\n",
        "            smean = K.mean(style_feats[i], axis=axis)\n",
        "            sstd = K.std(style_feats[i], axis=axis)\n",
        "\n",
        "            style_loss.append(\n",
        "                K.sum(K.square(gmean - smean)) +\n",
        "                K.sum(K.square(gstd - sstd))\n",
        "            )\n",
        "\n",
        "        return Reduction()(style_loss)\n",
        "\n",
        "    def build_decoder(self, input_shape):\n",
        "        feat = Input(input_shape)\n",
        "        kernel_size = 3\n",
        "\n",
        "        x = self.conv_block(feat, 512, kernel_size=kernel_size, up_sampling=True)\n",
        "\n",
        "        x = self.conv_block(x, 256, kernel_size=kernel_size)\n",
        "        x = self.conv_block(x, 256, kernel_size=kernel_size)\n",
        "        x = self.conv_block(x, 256, kernel_size=kernel_size)\n",
        "        x = self.conv_block(x, 256, kernel_size=kernel_size, up_sampling=True)\n",
        "\n",
        "        # x = self.conv_block(x, 128, kernel_size=kernel_size)\n",
        "        # x = self.conv_block(x, 128, kernel_size=kernel_size)\n",
        "        x = self.conv_block(x, 128, kernel_size=kernel_size)\n",
        "        x = self.conv_block(x, 128, kernel_size=kernel_size, up_sampling=True)\n",
        "\n",
        "        x = self.conv_block(x, 64, kernel_size=kernel_size)\n",
        "        x = self.conv_block(x, 64, kernel_size=kernel_size)\n",
        "\n",
        "        style_image = self.conv_block(x, 3, kernel_size=kernel_size, activation='linear')\n",
        "\n",
        "        model = Model(inputs=feat, outputs=style_image, name='decoder')\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "style_layer_names=[\n",
        "    'block1_conv1', 'block2_conv1',\n",
        "    'block3_conv1', 'block4_conv1',\n",
        "]\n",
        "last_layer='block4_conv1'\n",
        "pre_trained_model = 'vgg16'\n",
        "rst = 256\n",
        "data_gen = DataGen(BASE_DIR, 8, rst=rst, max_size=1500, multi_batch=False,\n",
        "                   normalize=True)\n",
        "smodel = SModel(BASE_DIR, None, 1e-4,\n",
        "                style_layer_names=style_layer_names,\n",
        "                last_layer=last_layer, \n",
        "                show_interval=5,\n",
        "                style_loss_weight=3.5,\n",
        "                pre_trained_model=pre_trained_model)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 6s 0us/step\n",
            "Encoder: vgg16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6hAej6NAZU1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ebc75e7c-0944-47f8-e7c8-dce7f2d2b468"
      },
      "source": [
        "smodel.load_weight()\n",
        "smodel.train(data_gen, 100, augment_factor=0)\n",
        "smodel.save_weight()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1500 samples\n",
            "Train epochs 1/100 - WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I3Dd4P1gQ6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smodel.load_weight()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD2bkp0OMhPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# smodel.save_weight()\n",
        "idx = np.random.randint(0, 300)\n",
        "sid = 15\n",
        "# cimg = data_gen.x[idx:idx+1]\n",
        "cimg = utils.http_get_img('https://github.com/elleryqueenhomels/arbitrary_style_transfer/blob/master/images/content/stata.jpg?raw=true', None)\n",
        "simg =  data_gen.y[sid:sid+1]\n",
        "gen = smodel.generate(cimg, simg)[0]\n",
        "gen = utils.deprocess(gen)\n",
        "cv2_imshow(gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcTZh9oyPNXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "urls = [\n",
        "    # 'https://github.com/elleryqueenhomels/arbitrary_style_transfer/raw/master/images/style_thumb/escher_sphere_thumb.jpg',\n",
        "    'https://1.bp.blogspot.com/-39XZDC2-ifQ/UxXqyjWlt-I/AAAAAAAAXzc/_rTksQDKmx8/s1600/Gleizes,+Albert,+Pablo_Picasso,+1909-10,+Figure++in+a+Chair,+Seated+Nude,+Woman.jpg',\n",
        "    'https://github.com/elleryqueenhomels/arbitrary_style_transfer/raw/master/images/style_thumb/udnie_thumb.jpg',\n",
        "    'https://github.com/elleryqueenhomels/arbitrary_style_transfer/raw/master/images/style_thumb/mosaic_thumb.jpg',\n",
        "    'https://github.com/elleryqueenhomels/arbitrary_style_transfer/raw/master/images/style_thumb/cat_thumb.jpg'\n",
        "]\n",
        "cv2_imshow(utils.deprocess(utils.de_norm(cimg[0])))\n",
        "for url in urls:\n",
        "    simg = utils.http_get_img(url, None)\n",
        "    cv2_imshow(utils.deprocess(utils.de_norm(simg[0])))\n",
        "    cv2_imshow(utils.deprocess(utils.de_norm(smodel.generate(cimg, simg)[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj7At9WFutJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from classification_models.keras import Classifiers\n",
        "\n",
        "vggnet, _ = Classifiers.get('vgg19')\n",
        "input_shape = (None, None, 3)\n",
        "model = vggnet(input_shape=input_shape,\n",
        "            weights='imagenet',\n",
        "            include_top=False)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WKTuBBSUeBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg19 import preprocess_input\n",
        "\n",
        "cv2_imshow((data_gen.y[0]))\n",
        "cv2_imshow(utils.deprocess(utils.de_norm(data_gen.y[0])))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}